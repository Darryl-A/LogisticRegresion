{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eab2814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a176ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "data = pd.read_csv('train_file.dat', delimiter = \"\t\", quoting = 3, header = None)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8629b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/darrylanthony/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Cleaning the dataset\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, 18506):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(df[1][i]))\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    allStop = stopwords.words('english')\n",
    "    allStop.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(allStop)]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07896136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ee1cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ee56069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14859"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a24f9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "273b0995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab166749",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5dfaa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 ...  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a24bbc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1458  257]\n",
      " [ 210 1777]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8738519719070773"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "235fb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking on the whole training dataset\n",
    "new_pred = lr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9344c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a491045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7522  984]\n",
      " [ 871 9129]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8997622392737491"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the accuracy of the model\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm2 = confusion_matrix(y, new_pred)\n",
    "print(cm2)\n",
    "accuracy_score(y,new_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c39344aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the test dataset\n",
    "test = pd.read_csv('test.dat', delimiter = \"\\t\", header=None, quoting = 3, skip_blank_lines=False)\n",
    "df2 = pd.DataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "913e2b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       0\n",
      "0      Perfect for new parents. We were able to keep ...\n",
      "1      Helps me know exactly how my babies day has go...\n",
      "2      I wanted an alternative to printing out daily ...\n",
      "3      My 3 month old son spend half of his days with...\n",
      "4      The Baby Tracker brand books are the absolute ...\n",
      "...                                                  ...\n",
      "18501  WTF. The pieces don't fit together, the instru...\n",
      "18502  I've gone through a couple of video baby monit...\n",
      "18503  This monitor is cheap and doesn't work well. O...\n",
      "18504  These monitors do not work at all, I even atte...\n",
      "18505  Short story, I was very disappointed with the ...\n",
      "\n",
      "[18506 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b38b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the dataset\n",
    "corpus2 = []\n",
    "for i in range(0, 18506):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(df2[0][i]))\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    allStop = stopwords.words('english')\n",
    "    allStop.remove('not')\n",
    "    review = [ps.stem(word) for word in review if not word in set(allStop)]\n",
    "    review = ' '.join(review)\n",
    "    corpus2.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5efc93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to vector representation\n",
    "X_ = cv.transform(corpus2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45c2509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14859"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "371a5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on the test file\n",
    "Y_Pred = lr.predict(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "58b358ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the prediction file to another file\n",
    "Y_Pred.tofile('pred7.dat', sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1be070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
